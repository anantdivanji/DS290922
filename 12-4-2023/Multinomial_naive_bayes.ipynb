{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea2de1f",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05c2f3",
   "metadata": {},
   "source": [
    "- Works very well with Text Data.\n",
    "- Target is discrete in nature so multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305d960",
   "metadata": {},
   "source": [
    "## Loading the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e9f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe5209",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024b68c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('horror-train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b59635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b5e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    40.349354\n",
       "MWS    30.869809\n",
       "HPL    28.780837\n",
       "Name: author, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['author'].value_counts(normalize = True ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00cf4009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text author\n",
       "0  This process, however, afforded me no means of...    EAP\n",
       "1  It never once occurred to me that the fumbling...    HPL\n",
       "2  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('id', axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6136a",
   "metadata": {},
   "source": [
    "## Text processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a06f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd0fa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e475b79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'process',\n",
       " 'however',\n",
       " 'afforded',\n",
       " 'me',\n",
       " 'no',\n",
       " 'means',\n",
       " 'of',\n",
       " 'ascertaining',\n",
       " 'the',\n",
       " 'dimensions',\n",
       " 'of',\n",
       " 'my',\n",
       " 'dungeon',\n",
       " 'as',\n",
       " 'I',\n",
       " 'might',\n",
       " 'make',\n",
       " 'its',\n",
       " 'circuit',\n",
       " 'and',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'point',\n",
       " 'whence',\n",
       " 'I',\n",
       " 'set',\n",
       " 'out',\n",
       " 'without',\n",
       " 'being',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'so',\n",
       " 'perfectly',\n",
       " 'uniform',\n",
       " 'seemed',\n",
       " 'the',\n",
       " 'wall']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047c0d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is example @ regextokenizer ! #.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'This is example @ regextokenizer ! #.'\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4450545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'example', 'regextokenizer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00c5f463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[This, process, however, afforded, me, no, mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[It, never, once, occurred, to, me, that, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[In, his, left, hand, was, a, gold, snuff, box...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[How, lovely, is, spring, As, we, looked, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[Finding, nothing, else, not, even, gold, the,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text author  \\\n",
       "0  This process, however, afforded me no means of...    EAP   \n",
       "1  It never once occurred to me that the fumbling...    HPL   \n",
       "2  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [This, process, however, afforded, me, no, mea...  \n",
       "1  [It, never, once, occurred, to, me, that, the,...  \n",
       "2  [In, his, left, hand, was, a, gold, snuff, box...  \n",
       "3  [How, lovely, is, spring, As, we, looked, from...  \n",
       "4  [Finding, nothing, else, not, even, gold, the,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_tokenized'] = data['text'].apply(lambda t : tokenizer.tokenize(t))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6176c",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9572dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b20e4e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[thi, process, howev, afford, me, no, mean, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, onc, occur, to, me, that, the, fum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, hi, left, hand, wa, a, gold, snuff, box, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[how, love, is, spring, as, we, look, from, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[find, noth, el, not, even, gold, the, superin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text author  \\\n",
       "0  This process, however, afforded me no means of...    EAP   \n",
       "1  It never once occurred to me that the fumbling...    HPL   \n",
       "2  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [thi, process, howev, afford, me, no, mean, of...  \n",
       "1  [it, never, onc, occur, to, me, that, the, fum...  \n",
       "2  [in, hi, left, hand, wa, a, gold, snuff, box, ...  \n",
       "3  [how, love, is, spring, as, we, look, from, wi...  \n",
       "4  [find, noth, el, not, even, gold, the, superin...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_tokenized'] = data['text_tokenized'].apply(lambda l : [stemmer.stem(word) for word in l])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624a987",
   "metadata": {},
   "source": [
    "## convert the text_tokenized into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c8df761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[thi, process, howev, afford, me, no, mean, of...</td>\n",
       "      <td>thi process howev afford me no mean of ascerta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[it, never, onc, occur, to, me, that, the, fum...</td>\n",
       "      <td>it never onc occur to me that the fumbl might ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[in, hi, left, hand, wa, a, gold, snuff, box, ...</td>\n",
       "      <td>in hi left hand wa a gold snuff box from which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[how, love, is, spring, as, we, look, from, wi...</td>\n",
       "      <td>how love is spring as we look from windsor ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[find, noth, el, not, even, gold, the, superin...</td>\n",
       "      <td>find noth el not even gold the superintend aba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text author  \\\n",
       "0  This process, however, afforded me no means of...    EAP   \n",
       "1  It never once occurred to me that the fumbling...    HPL   \n",
       "2  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [thi, process, howev, afford, me, no, mean, of...   \n",
       "1  [it, never, onc, occur, to, me, that, the, fum...   \n",
       "2  [in, hi, left, hand, wa, a, gold, snuff, box, ...   \n",
       "3  [how, love, is, spring, as, we, look, from, wi...   \n",
       "4  [find, noth, el, not, even, gold, the, superin...   \n",
       "\n",
       "                                           text_sent  \n",
       "0  thi process howev afford me no mean of ascerta...  \n",
       "1  it never onc occur to me that the fumbl might ...  \n",
       "2  in hi left hand wa a gold snuff box from which...  \n",
       "3  how love is spring as we look from windsor ter...  \n",
       "4  find noth el not even gold the superintend aba...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_sent'] = data['text_tokenized'].apply(lambda l : \" \".join(l))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1949a43",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3939542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d74eefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.fit_transform(data['text_sent']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478b1eb",
   "metadata": {},
   "source": [
    "## Save the vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25bbd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec.fit_transform(data['text_sent']).toarray()\n",
    "y = data['author']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72470ed",
   "metadata": {},
   "source": [
    "## Split the data into train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00255432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2ec19",
   "metadata": {},
   "source": [
    "## Apply Multinomial NB on X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39a32a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aea4e194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50955f7d",
   "metadata": {},
   "source": [
    "## Perform Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e49200fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MWS', 'EAP', 'HPL', ..., 'EAP', 'HPL', 'EAP'], dtype='<U3')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mnb.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96729a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cfe4f",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b77b85e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323118828736806"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814214f",
   "metadata": {},
   "source": [
    "## Inorder to increase the accuracy\n",
    "\n",
    "1. Consider stopwards removal\n",
    "2. Lowercase conversion\n",
    "3. TFIDF Vectorization\n",
    "4. etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8ad19",
   "metadata": {},
   "source": [
    "In Text processing we did not perform lowercase conversion, we did not remove stopwords.   \n",
    "Without performing these steps we just vectorized and applied machine learning.   \n",
    "Do you think that this is a wrong approach\n",
    "\n",
    "\n",
    "- No approach in Data Science is a wrong appraoch \n",
    "### Why?\n",
    "- The  data Science project building approach is a repetative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e286048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
