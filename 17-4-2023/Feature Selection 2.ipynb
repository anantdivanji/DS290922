{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Feature Selection 2\n",
    "* Introduction to Wrapper Methods\n",
    "* Advantages of Wrapper Methods\n",
    "* Process of Wrapper Methods\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Methods\n",
    "* Using iterative process, we will try to figure out best subset of features for which ML algorithms is giving best accuracy.\n",
    "* This process is dependent on ML algo.\n",
    "* Whenever we change the algo, the selected features also change.\n",
    "\n",
    "### Advantages\n",
    "* It does feature selection based on the accuracy of the model (dependent on ML algo)\n",
    "* It also accounts for interaction among features\n",
    "\n",
    "### Process of applying Wrapper Methods\n",
    "* <b>Search</b>  for subset of features\n",
    "* <b>Build</b> model using the subset\n",
    "* <b>Evaluate</b> trained model with chosen metrices\n",
    "* <b>Iterate</b> repeat till you succeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching subset of features\n",
    "* Start Small - Start with one feature & keep adding. Stop where you model stops improving further.\n",
    "* Start Big - Start with all features & keep removing.\n",
    "* Ramdomize or try all possible combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/winequality-white.csv', sep=';')\n",
    "def f(r):\n",
    "    if r <= 3:\n",
    "        return 1\n",
    "    elif r<= 6:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df.quality = df.quality.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763265306122449\n",
      "0.7681632653061224\n",
      "0.7624489795918368\n",
      "0.7706122448979592\n",
      "0.8081632653061225\n",
      "0.8016326530612244\n",
      "0.8\n",
      "0.8195918367346938\n",
      "0.8130612244897959\n",
      "0.8261224489795919\n",
      "0.8244897959183674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try_features = []\n",
    "for feature in features:\n",
    "    try_features.append(feature)\n",
    "    dt = DecisionTreeClassifier()\n",
    "    trainX, testX, trainY, testY = train_test_split(df[try_features], df.quality)\n",
    "    dt.fit(trainX, trainY)\n",
    "    print (dt.score(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantage of this process\n",
    "* Lot of computations required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* Mlextend is additional scikit packge which makes feature selection easy https://pypi.org/project/mlxtend/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SequentialFeatureSelector(k_features=5, estimator=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
       "                          estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                           criterion='gini',\n",
       "                                                           max_depth=None,\n",
       "                                                           max_features=None,\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           min_impurity_decrease=0.0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=1,\n",
       "                                                           min_samples_split=2,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           presort=False,\n",
       "                                                           random_state=None,\n",
       "                                                           splitter='best'),\n",
       "                          floating=False, forward=True, k_features=5, n_jobs=1,\n",
       "                          pre_dispatch='2*n_jobs', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fixed acidity', 'volatile acidity', 'residual sugar', 'sulphates', 'alcohol')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8053352632961726"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.8056084883307666 ('volatile acidity', 'chlorides', 'sulphates', 'alcohol')\n",
      "5 0.8026126889566394 ('fixed acidity', 'volatile acidity', 'residual sugar', 'sulphates', 'alcohol')\n",
      "6 0.8056147815126525 ('citric acid', 'residual sugar', 'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'alcohol')\n",
      "7 0.8154059006614137 ('fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'pH', 'sulphates', 'alcohol')\n",
      "8 0.8064151892246059 ('fixed acidity', 'volatile acidity', 'residual sugar', 'chlorides', 'total sulfur dioxide', 'density', 'pH', 'alcohol')\n",
      "9 0.80722780653548 ('fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'pH', 'sulphates', 'alcohol')\n"
     ]
    }
   ],
   "source": [
    "for k in range(4,10):\n",
    "    sfs = SequentialFeatureSelector(k_features=k, estimator=DecisionTreeClassifier())\n",
    "    sfs.fit(trainX, trainY)\n",
    "    print (k,sfs.k_score_, sfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs = ExhaustiveFeatureSelector(estimator=DecisionTreeClassifier(), min_features=4, max_features=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 1815/1815"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExhaustiveFeatureSelector(clone_estimator=True, cv=5,\n",
       "                          estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                           criterion='gini',\n",
       "                                                           max_depth=None,\n",
       "                                                           max_features=None,\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           min_impurity_decrease=0.0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=1,\n",
       "                                                           min_samples_split=2,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           presort=False,\n",
       "                                                           random_state=None,\n",
       "                                                           splitter='best'),\n",
       "                          max_features=10, min_features=4, n_jobs=1,\n",
       "                          pre_dispatch='2*n_jobs', print_progress=True,\n",
       "                          scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'density',\n",
       " 'pH')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs.best_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8184024394617462"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs = ExhaustiveFeatureSelector(estimator=DecisionTreeClassifier(), min_features=4, max_features=10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
